//
// Copyright 2020 Swiftkube Project
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
// http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
//

///
/// Generated by Swiftkube:ModelGen
/// Kubernetes v1.24.10
/// core.v1.TopologySpreadConstraint
///

import Foundation

// MARK: - core.v1.TopologySpreadConstraint

public extension core.v1 {

	///
	/// TopologySpreadConstraint specifies how to spread matching pods among the given topology.
	///
	struct TopologySpreadConstraint: KubernetesResource {
		///
		/// LabelSelector is used to find matching pods. Pods that match this label selector are counted to determine the number of pods in their corresponding topology domain.
		///
		public var labelSelector: meta.v1.LabelSelector?
		///
		/// MaxSkew describes the degree to which pods may be unevenly distributed. When `whenUnsatisfiable=DoNotSchedule`, it is the maximum permitted difference between the number of matching pods in the target topology and the global minimum. The global minimum is the minimum number of matching pods in an eligible domain or zero if the number of eligible domains is less than MinDomains. For example, in a 3-zone cluster, MaxSkew is set to 1, and pods with the same labelSelector spread as 2/2/1: In this case, the global minimum is 1. | zone1 | zone2 | zone3 | |  P P  |  P P  |   P   | - if MaxSkew is 1, incoming pod can only be scheduled to zone3 to become 2/2/2; scheduling it onto zone1(zone2) would make the ActualSkew(3-1) on zone1(zone2) violate MaxSkew(1). - if MaxSkew is 2, incoming pod can be scheduled onto any zone. When `whenUnsatisfiable=ScheduleAnyway`, it is used to give higher precedence to topologies that satisfy it. It's a required field. Default value is 1 and 0 is not allowed.
		///
		public var maxSkew: Int32
		///
		/// MinDomains indicates a minimum number of eligible domains. When the number of eligible domains with matching topology keys is less than minDomains, Pod Topology Spread treats "global minimum" as 0, and then the calculation of Skew is performed. And when the number of eligible domains with matching topology keys equals or greater than minDomains, this value has no effect on scheduling. As a result, when the number of eligible domains is less than minDomains, scheduler won't schedule more than maxSkew Pods to those domains. If value is nil, the constraint behaves as if MinDomains is equal to 1. Valid values are integers greater than 0. When value is not nil, WhenUnsatisfiable must be DoNotSchedule.
		///
		/// For example, in a 3-zone cluster, MaxSkew is set to 2, MinDomains is set to 5 and pods with the same labelSelector spread as 2/2/2: | zone1 | zone2 | zone3 | |  P P  |  P P  |  P P  | The number of domains is less than 5(MinDomains), so "global minimum" is treated as 0. In this situation, new pod with the same labelSelector cannot be scheduled, because computed skew will be 3(3 - 0) if new Pod is scheduled to any of the three zones, it will violate MaxSkew.
		///
		/// This is an alpha field and requires enabling MinDomainsInPodTopologySpread feature gate.
		///
		public var minDomains: Int32?
		///
		/// TopologyKey is the key of node labels. Nodes that have a label with this key and identical values are considered to be in the same topology. We consider each <key, value> as a "bucket", and try to put balanced number of pods into each bucket. We define a domain as a particular instance of a topology. Also, we define an eligible domain as a domain whose nodes match the node selector. e.g. If TopologyKey is "kubernetes.io/hostname", each Node is a domain of that topology. And, if TopologyKey is "topology.kubernetes.io/zone", each zone is a domain of that topology. It's a required field.
		///
		public var topologyKey: String
		///
		/// WhenUnsatisfiable indicates how to deal with a pod if it doesn't satisfy the spread constraint. - DoNotSchedule (default) tells the scheduler not to schedule it. - ScheduleAnyway tells the scheduler to schedule the pod in any location,
		///   but giving higher precedence to topologies that would help reduce the
		///   skew.
		/// A constraint is considered "Unsatisfiable" for an incoming pod if and only if every possible node assignment for that pod would violate "MaxSkew" on some topology. For example, in a 3-zone cluster, MaxSkew is set to 1, and pods with the same labelSelector spread as 3/1/1: | zone1 | zone2 | zone3 | | P P P |   P   |   P   | If WhenUnsatisfiable is set to DoNotSchedule, incoming pod can only be scheduled to zone2(zone3) to become 3/2/1(3/1/2) as ActualSkew(2-1) on zone2(zone3) satisfies MaxSkew(1). In other words, the cluster can still be imbalanced, but scheduler won't make it *more* imbalanced. It's a required field.
		///
		///
		///
		public var whenUnsatisfiable: String
		///
		/// Default memberwise initializer
		///
		public init(
			labelSelector: meta.v1.LabelSelector? = nil,
			maxSkew: Int32,
			minDomains: Int32? = nil,
			topologyKey: String,
			whenUnsatisfiable: String
		) {
			self.labelSelector = labelSelector
			self.maxSkew = maxSkew
			self.minDomains = minDomains
			self.topologyKey = topologyKey
			self.whenUnsatisfiable = whenUnsatisfiable
		}
	}
}

///
/// Codable conformance
///
public extension core.v1.TopologySpreadConstraint {

	private enum CodingKeys: String, CodingKey {

		case labelSelector = "labelSelector"
		case maxSkew = "maxSkew"
		case minDomains = "minDomains"
		case topologyKey = "topologyKey"
		case whenUnsatisfiable = "whenUnsatisfiable"
	}

	init(from decoder: Decoder) throws {
		let container = try decoder.container(keyedBy: CodingKeys.self)
		self.labelSelector = try container.decodeIfPresent(meta.v1.LabelSelector.self, forKey: .labelSelector)
		self.maxSkew = try container.decode(Int32.self, forKey: .maxSkew)
		self.minDomains = try container.decodeIfPresent(Int32.self, forKey: .minDomains)
		self.topologyKey = try container.decode(String.self, forKey: .topologyKey)
		self.whenUnsatisfiable = try container.decode(String.self, forKey: .whenUnsatisfiable)
	}

	func encode(to encoder: Encoder) throws {
		var encodingContainer = encoder.container(keyedBy: CodingKeys.self)

		try encodingContainer.encode(labelSelector, forKey: .labelSelector)
		try encodingContainer.encode(maxSkew, forKey: .maxSkew)
		try encodingContainer.encode(minDomains, forKey: .minDomains)
		try encodingContainer.encode(topologyKey, forKey: .topologyKey)
		try encodingContainer.encode(whenUnsatisfiable, forKey: .whenUnsatisfiable)
	}
}
